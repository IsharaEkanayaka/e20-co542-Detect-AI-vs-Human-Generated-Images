{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":91198,"databundleVersionId":10884264,"sourceType":"competition"},{"sourceId":10550636,"sourceType":"datasetVersion","datasetId":6412205}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":9769.724299,"end_time":"2025-02-05T11:55:30.995749","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-02-05T09:12:41.271450","version":"2.6.0"},"colab":{"provenance":[],"toc_visible":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"0c913c3a","cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport cv2\n\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import StepLR\n\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nfrom sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\n\nfrom tqdm import tqdm\nimport wandb\nfrom kaggle_secrets import UserSecretsClient\n","metadata":{"execution":{"iopub.status.busy":"2025-02-24T11:55:09.782094Z","iopub.execute_input":"2025-02-24T11:55:09.782459Z","iopub.status.idle":"2025-02-24T11:55:26.115127Z","shell.execute_reply.started":"2025-02-24T11:55:09.782424Z","shell.execute_reply":"2025-02-24T11:55:26.114209Z"},"papermill":{"duration":8.982354,"end_time":"2025-02-05T09:12:52.924452","exception":false,"start_time":"2025-02-05T09:12:43.942098","status":"completed"},"tags":[],"id":"0c913c3a","trusted":true},"outputs":[],"execution_count":1},{"id":"df5690ef-8707-49c9-ae18-c6393e5b90be","cell_type":"code","source":"# Initialize W&B with Kaggle secrets\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"WANDB_KEY\")\nwandb.login(key=secret_value_0)\n\n# Initialize W&B run\nrun = wandb.init(project=\"ai-vs-human-generated-images\", name=\"image-classfication\", entity=\"DevGru\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T11:55:26.116286Z","iopub.execute_input":"2025-02-24T11:55:26.116618Z","iopub.status.idle":"2025-02-24T11:55:39.027080Z","shell.execute_reply.started":"2025-02-24T11:55:26.116583Z","shell.execute_reply":"2025-02-24T11:55:39.025841Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33me20456\u001b[0m (\u001b[33mDevGru\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250224_115532-nzfhr11w</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/DevGru/ai-vs-human-generated-images/runs/nzfhr11w' target=\"_blank\">image-classfication</a></strong> to <a href='https://wandb.ai/DevGru/ai-vs-human-generated-images' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/DevGru/ai-vs-human-generated-images' target=\"_blank\">https://wandb.ai/DevGru/ai-vs-human-generated-images</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/DevGru/ai-vs-human-generated-images/runs/nzfhr11w' target=\"_blank\">https://wandb.ai/DevGru/ai-vs-human-generated-images/runs/nzfhr11w</a>"},"metadata":{}}],"execution_count":2},{"id":"6edd8f6b","cell_type":"code","source":"# Define paths to dataset files\npath = '/kaggle/input/ai-vs-human-generated-dataset'\ntrain_csv = '/kaggle/input/detect-ai-vs-human-generated-images/train.csv'\ntest_csv = '/kaggle/input/detect-ai-vs-human-generated-images/test.csv'\n\n# Load the training and test datasets\ntrain = pd.read_csv(train_csv)\ntest = pd.read_csv(test_csv)\n\n# Print dataset shapes\nprint(f'Training dataset shape: {train.shape}')\nprint(f'Test dataset shape: {test.shape}')\n\n# Preprocess column names for consistency\ntrain = train[['file_name', 'label']]\ntrain.columns = ['id', 'label']\n\n# Display columns for reference\nprint(\"Train columns:\", train.columns)\nprint(\"Test columns:\", test.columns)","metadata":{"papermill":{"duration":0.18016,"end_time":"2025-02-05T09:12:53.108100","exception":false,"start_time":"2025-02-05T09:12:52.927940","status":"completed"},"tags":[],"id":"6edd8f6b","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9d48fd65-233b-4ead-9bf9-b674318ab762","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T11:55:39.029459Z","iopub.execute_input":"2025-02-24T11:55:39.029699Z","iopub.status.idle":"2025-02-24T11:55:39.476637Z","shell.execute_reply.started":"2025-02-24T11:55:39.029677Z","shell.execute_reply":"2025-02-24T11:55:39.475854Z"}},"outputs":[{"name":"stdout","text":"Training dataset shape: (79950, 3)\nTest dataset shape: (5540, 1)\nTrain columns: Index(['id', 'label'], dtype='object')\nTest columns: Index(['id'], dtype='object')\n","output_type":"stream"}],"execution_count":3},{"id":"YB9OZB3nY-EY","cell_type":"code","source":"# Split the training data into training and validation sets (95% train, 5% validation)\ntrain_df, val_df = train_test_split(\n    train,\n    test_size=0.05,\n    random_state=42,\n    stratify=train['label']\n)\n\n# Print shapes of the splits\nprint(f'Train shape: {train_df.shape}')\nprint(f'Validation shape: {val_df.shape}')\n\n# Check class distribution in both sets\nprint(\"\\nTrain class distribution:\")\nprint(train_df['label'].value_counts(normalize=True))\n\nprint(\"\\nValidation class distribution:\")\nprint(val_df['label'].value_counts(normalize=True))","metadata":{"id":"YB9OZB3nY-EY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4e413977-d80d-461e-a1ec-104c2ed5a7ff","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T11:55:39.477886Z","iopub.execute_input":"2025-02-24T11:55:39.478231Z","iopub.status.idle":"2025-02-24T11:55:39.521564Z","shell.execute_reply.started":"2025-02-24T11:55:39.478196Z","shell.execute_reply":"2025-02-24T11:55:39.520675Z"}},"outputs":[{"name":"stdout","text":"Train shape: (75952, 2)\nValidation shape: (3998, 2)\n\nTrain class distribution:\nlabel\n0    0.5\n1    0.5\nName: proportion, dtype: float64\n\nValidation class distribution:\nlabel\n0    0.5\n1    0.5\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":4},{"id":"AMYBOpL4ZWY_","cell_type":"code","source":"# Training augmentations\ntrain_transforms = transforms.Compose([\n    transforms.Resize(232),  # Resize to match ConvNeXt preprocessing\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Validation and Test transforms\nval_test_transforms = transforms.Compose([\n    transforms.Resize(232),  # Resize to 232 as per ConvNeXt documentation\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"id":"AMYBOpL4ZWY_","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T11:55:39.522479Z","iopub.execute_input":"2025-02-24T11:55:39.522788Z","iopub.status.idle":"2025-02-24T11:55:39.529124Z","shell.execute_reply.started":"2025-02-24T11:55:39.522737Z","shell.execute_reply":"2025-02-24T11:55:39.528332Z"}},"outputs":[],"execution_count":5},{"id":"a84LpT9_ecTO","cell_type":"code","source":"# Dataset class for training and validation\nclass AIImageDataset(Dataset):\n    def __init__(self, dataframe, root_dir, transform=None):\n        self.dataframe = dataframe\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(self.root_dir, self.dataframe.iloc[idx, 0])\n        image = Image.open(img_name).convert('RGB')\n\n        if self.transform:\n            image = self.transform(image)\n\n        label = self.dataframe.iloc[idx, 1]\n        return image, label\n\n# Dataset class for inference (validation and test)\nclass TestAIImageDataset(Dataset):\n    def __init__(self, file_list, transform=None):\n        self.file_list = file_list\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.file_list)\n\n    def __getitem__(self, idx):\n        img_path = self.file_list[idx]\n        img = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        return img, os.path.basename(img_path)  # Return image and filename","metadata":{"id":"a84LpT9_ecTO","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T11:55:39.530032Z","iopub.execute_input":"2025-02-24T11:55:39.530261Z","iopub.status.idle":"2025-02-24T11:55:39.547821Z","shell.execute_reply.started":"2025-02-24T11:55:39.530230Z","shell.execute_reply":"2025-02-24T11:55:39.547037Z"}},"outputs":[],"execution_count":6},{"id":"YP1-SoSHefAo","cell_type":"code","source":"# Create datasets\ntrain_dataset = AIImageDataset(train_df, root_dir=path, transform=train_transforms)\n\n# For validation, create a list of file paths and store labels separately\nval_file_list = [os.path.join(path, fname) for fname in val_df['id']]\nval_labels = val_df['label'].values  # Store labels separately for later use\nval_dataset = TestAIImageDataset(file_list=val_file_list, transform=val_test_transforms)\n\n# For testing, create a list of file paths\ntest_file_list = [os.path.join(path, fname) for fname in test['id']]\ntest_dataset = TestAIImageDataset(file_list=test_file_list, transform=val_test_transforms)\n\nprint(f\"Training dataset size: {len(train_dataset)}\")\nprint(f\"Validation dataset size: {len(val_dataset)}\")\nprint(f\"Test dataset size: {len(test_dataset)}\")\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)","metadata":{"id":"YP1-SoSHefAo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3b44cb81-d17b-499a-eaae-af45345bd824","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T11:55:39.548638Z","iopub.execute_input":"2025-02-24T11:55:39.548933Z","iopub.status.idle":"2025-02-24T11:55:39.582039Z","shell.execute_reply.started":"2025-02-24T11:55:39.548909Z","shell.execute_reply":"2025-02-24T11:55:39.581289Z"}},"outputs":[{"name":"stdout","text":"Training dataset size: 75952\nValidation dataset size: 3998\nTest dataset size: 5540\n","output_type":"stream"}],"execution_count":7},{"id":"4LTWHu2HejMi","cell_type":"code","source":"# Load pretrained ConvNeXt Base model\nmodel = models.convnext_base(weights=\"DEFAULT\")\n\n# Freeze all layers initially\nfor param in model.features.parameters():\n    param.requires_grad = False\n\n# Unfreeze the last two stages\nfor param in model.features[-2:].parameters():\n    param.requires_grad = True\n\n# Replace the classifier head with a custom one\nmodel.classifier = nn.Sequential(\n    nn.AdaptiveAvgPool2d((1, 1)),  # Global average pooling\n    nn.Flatten(),                  # Flatten the tensor\n    nn.BatchNorm1d(1024),          # Add BatchNorm here\n    nn.Linear(1024, 512),          # First fully connected layer\n    nn.ReLU(),                     # Activation function\n    nn.Dropout(0.4),               # Dropout for regularization\n    nn.Linear(512, 2)              # Output layer (binary classification)\n)\n\n# Move the model to gpu\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n# Define loss function, optimizer, and learning rate scheduler\noptimizer = torch.optim.AdamW([\n    {'params': model.features[-2:].parameters(), 'lr': 1e-5},  # Lower LR for backbone\n    {'params': model.classifier.parameters(), 'lr': 1e-4}      # Higher LR for classifier\n])\n\ncriterion = nn.CrossEntropyLoss()\nscheduler = StepLR(optimizer, step_size=5, gamma=0.7)","metadata":{"id":"4LTWHu2HejMi","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T11:55:39.582847Z","iopub.execute_input":"2025-02-24T11:55:39.583147Z","iopub.status.idle":"2025-02-24T11:55:41.588162Z","shell.execute_reply.started":"2025-02-24T11:55:39.583112Z","shell.execute_reply":"2025-02-24T11:55:41.587202Z"}},"outputs":[],"execution_count":8},{"id":"odVSWQSaiaHD","cell_type":"code","source":"print(\"Training Start\")","metadata":{"id":"odVSWQSaiaHD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c80233f1-0428-4fa2-bf8e-09f9fc38f87f","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T11:55:41.590546Z","iopub.execute_input":"2025-02-24T11:55:41.590817Z","iopub.status.idle":"2025-02-24T11:55:41.596462Z","shell.execute_reply.started":"2025-02-24T11:55:41.590794Z","shell.execute_reply":"2025-02-24T11:55:41.595574Z"}},"outputs":[{"name":"stdout","text":"Training Start\n","output_type":"stream"}],"execution_count":9},{"id":"6Y1DxFH1ib6_","cell_type":"code","source":"\n# Training Loop\nepochs = 12\n\ntrain_losses, train_accuracies, val_losses, val_accuracies, val_f1s = [], [], [], [], []\n\nfor epoch in range(epochs):\n    # -- Training --\n    model.train()\n    epoch_loss = 0.0\n    epoch_accuracy = 0.0\n\n    for data, label in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n        data, label = data.to(device), label.to(device)\n\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, label)\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n        preds = output.argmax(dim=1)\n        acc = (preds == label).float().mean().item()\n        epoch_accuracy += acc\n\n    epoch_loss /= len(train_loader)\n    epoch_accuracy /= len(train_loader)\n\n    train_losses.append(epoch_loss)\n    train_accuracies.append(epoch_accuracy)\n\n    # -- Validation --\n    model.eval()\n    val_loss = 0.0\n    val_acc = 0.0\n    val_pred_classes = []  # To store predictions\n    val_labels_list = []   # To store true labels\n\n    with torch.no_grad():\n        for i, (data, _) in enumerate(tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}\")):\n            data = data.to(device)\n            output = model(data)\n\n            # Get true labels from val_df\n            batch_labels = val_labels[i * val_loader.batch_size : (i + 1) * val_loader.batch_size]\n            batch_labels = torch.tensor(batch_labels, device=device)\n\n            # Compute loss\n            loss = criterion(output, batch_labels)\n            val_loss += loss.item()\n\n            # Compute predictions and accuracy\n            preds = output.argmax(dim=1)\n            acc = (preds == batch_labels).float().mean().item()\n            val_acc += acc\n\n            # Store predictions and true labels\n            val_pred_classes.extend(preds.cpu().numpy())\n            val_labels_list.extend(batch_labels.cpu().numpy())\n\n    # Compute average validation metrics\n    val_loss /= len(val_loader)\n    val_acc /= len(val_loader)\n    val_f1 = f1_score(val_labels_list, val_pred_classes, average='binary')  # Binary classification\n\n    # Append metrics\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    val_f1s.append(val_f1)\n\n    print(\n        f\"Epoch [{epoch+1}/{epochs}] \"\n        f\"Train Loss: {epoch_loss:.4f} | Train Acc: {epoch_accuracy:.4f} | \"\n        f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Val F1: {val_f1:.4f}\"\n    )\n\n    # Step the learning rate scheduler\n    scheduler.step()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Y1DxFH1ib6_","outputId":"b497606b-b5a3-4b16-b906-072c63c1cf78","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T11:55:41.597364Z","iopub.execute_input":"2025-02-24T11:55:41.597569Z","iopub.status.idle":"2025-02-24T14:37:31.633566Z","shell.execute_reply.started":"2025-02-24T11:55:41.597551Z","shell.execute_reply":"2025-02-24T14:37:31.632661Z"}},"outputs":[{"name":"stderr","text":"Training Epoch 1: 100%|██████████| 2374/2374 [13:01<00:00,  3.04it/s]\nValidation Epoch 1: 100%|██████████| 125/125 [00:29<00:00,  4.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/12] Train Loss: 0.2072 | Train Acc: 0.9158 | Val Loss: 0.0902 | Val Acc: 0.9657 | Val F1: 0.9658\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 2: 100%|██████████| 2374/2374 [12:58<00:00,  3.05it/s]\nValidation Epoch 2: 100%|██████████| 125/125 [00:29<00:00,  4.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/12] Train Loss: 0.1497 | Train Acc: 0.9400 | Val Loss: 0.0863 | Val Acc: 0.9645 | Val F1: 0.9650\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 3: 100%|██████████| 2374/2374 [12:58<00:00,  3.05it/s]\nValidation Epoch 3: 100%|██████████| 125/125 [00:29<00:00,  4.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/12] Train Loss: 0.1339 | Train Acc: 0.9458 | Val Loss: 0.0807 | Val Acc: 0.9665 | Val F1: 0.9670\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 4: 100%|██████████| 2374/2374 [12:58<00:00,  3.05it/s]\nValidation Epoch 4: 100%|██████████| 125/125 [00:29<00:00,  4.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/12] Train Loss: 0.1233 | Train Acc: 0.9499 | Val Loss: 0.0721 | Val Acc: 0.9710 | Val F1: 0.9711\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 5: 100%|██████████| 2374/2374 [12:57<00:00,  3.05it/s]\nValidation Epoch 5: 100%|██████████| 125/125 [00:29<00:00,  4.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/12] Train Loss: 0.1186 | Train Acc: 0.9521 | Val Loss: 0.0814 | Val Acc: 0.9690 | Val F1: 0.9696\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 6: 100%|██████████| 2374/2374 [12:58<00:00,  3.05it/s]\nValidation Epoch 6: 100%|██████████| 125/125 [00:29<00:00,  4.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [6/12] Train Loss: 0.1114 | Train Acc: 0.9551 | Val Loss: 0.0667 | Val Acc: 0.9725 | Val F1: 0.9728\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 7: 100%|██████████| 2374/2374 [12:58<00:00,  3.05it/s]\nValidation Epoch 7: 100%|██████████| 125/125 [00:29<00:00,  4.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [7/12] Train Loss: 0.1073 | Train Acc: 0.9579 | Val Loss: 0.0632 | Val Acc: 0.9735 | Val F1: 0.9739\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 8: 100%|██████████| 2374/2374 [13:00<00:00,  3.04it/s]\nValidation Epoch 8: 100%|██████████| 125/125 [00:29<00:00,  4.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [8/12] Train Loss: 0.1044 | Train Acc: 0.9586 | Val Loss: 0.0605 | Val Acc: 0.9745 | Val F1: 0.9747\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 9: 100%|██████████| 2374/2374 [13:02<00:00,  3.03it/s]\nValidation Epoch 9: 100%|██████████| 125/125 [00:29<00:00,  4.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [9/12] Train Loss: 0.1024 | Train Acc: 0.9587 | Val Loss: 0.0656 | Val Acc: 0.9737 | Val F1: 0.9741\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 10: 100%|██████████| 2374/2374 [13:01<00:00,  3.04it/s]\nValidation Epoch 10: 100%|██████████| 125/125 [00:29<00:00,  4.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [10/12] Train Loss: 0.1000 | Train Acc: 0.9604 | Val Loss: 0.0598 | Val Acc: 0.9757 | Val F1: 0.9760\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 11: 100%|██████████| 2374/2374 [13:00<00:00,  3.04it/s]\nValidation Epoch 11: 100%|██████████| 125/125 [00:29<00:00,  4.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [11/12] Train Loss: 0.0976 | Train Acc: 0.9612 | Val Loss: 0.0552 | Val Acc: 0.9775 | Val F1: 0.9776\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 12: 100%|██████████| 2374/2374 [12:59<00:00,  3.04it/s]\nValidation Epoch 12: 100%|██████████| 125/125 [00:29<00:00,  4.23it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [12/12] Train Loss: 0.0913 | Train Acc: 0.9639 | Val Loss: 0.0574 | Val Acc: 0.9775 | Val F1: 0.9778\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":10},{"id":"8U-dupGAmGWE","cell_type":"code","source":"# Generate predictions and logits for the test set\nmodel.eval()\ntest_logits = []  # To store logits\ntest_pred_classes = []\n\nwith torch.no_grad():\n    for data, _ in tqdm(test_loader, desc=\"Generating Test Predictions\"):\n        data = data.to(device)\n        output = model(data)  # Raw logits (before softmax)\n\n        # Save logits\n        test_logits.extend(output.cpu().numpy())  # Store raw logits\n\n        # Get predicted class (0 or 1)\n        preds = output.argmax(dim=1)\n        test_pred_classes.extend(preds.cpu().numpy())\n\n# Convert logits to a DataFrame\nlogits_df = pd.DataFrame(test_logits, columns=['logit_class_0', 'logit_class_1'])\nlogits_df['id'] = test['id'].values  # Add image IDs for reference\n\n# Save logits to a CSV file\nlogits_df.to_csv('test_logits.csv', index=False)\n\n# Add predictions to the test DataFrame\ntest['label'] = test_pred_classes\ntest[['id', 'label']].to_csv('submission.csv', index=False)\n\nprint(\"Test logits saved to 'test_logits.csv'\")\nprint(\"Test predictions saved to 'submission.csv'\")","metadata":{"id":"8U-dupGAmGWE","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:37:31.634563Z","iopub.execute_input":"2025-02-24T14:37:31.634850Z","iopub.status.idle":"2025-02-24T14:38:48.866326Z","shell.execute_reply.started":"2025-02-24T14:37:31.634812Z","shell.execute_reply":"2025-02-24T14:38:48.865396Z"}},"outputs":[{"name":"stderr","text":"Generating Test Predictions: 100%|██████████| 174/174 [01:17<00:00,  2.26it/s]","output_type":"stream"},{"name":"stdout","text":"Test logits saved to 'test_logits.csv'\nTest predictions saved to 'submission.csv'\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":11},{"id":"JK9f6nPSmLz4","cell_type":"code","source":"# # Generate predictions for the test set\n# model.eval()\n# test_pred_classes = []\n\n# with torch.no_grad():\n#     for data, _ in tqdm(test_loader, desc=\"Generating Test Predictions\"):\n#         data = data.to(device)\n#         output = model(data)\n#         preds = output.argmax(dim=1)  # Get predicted class (0 or 1)\n#         test_pred_classes.extend(preds.cpu().numpy())\n\n# # Add predictions to the test DataFrame\n# test['label'] = test_pred_classes\n\n# # Save predictions to a CSV file\n# test[['id', 'label']].to_csv('submission.csv', index=False)\n# print(\"Test predictions saved to 'submission.csv'\")","metadata":{"id":"JK9f6nPSmLz4","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:38:48.867252Z","iopub.execute_input":"2025-02-24T14:38:48.867558Z","iopub.status.idle":"2025-02-24T14:38:48.872006Z","shell.execute_reply.started":"2025-02-24T14:38:48.867527Z","shell.execute_reply":"2025-02-24T14:38:48.871118Z"}},"outputs":[],"execution_count":12},{"id":"q5nzrHDfmNgb","cell_type":"code","source":"pd.read_csv('submission.csv')['label'].value_counts()","metadata":{"id":"q5nzrHDfmNgb","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T14:38:48.872912Z","iopub.execute_input":"2025-02-24T14:38:48.873109Z","iopub.status.idle":"2025-02-24T14:38:48.899910Z","shell.execute_reply.started":"2025-02-24T14:38:48.873092Z","shell.execute_reply":"2025-02-24T14:38:48.899032Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"label\n0    3532\n1    2008\nName: count, dtype: int64"},"metadata":{}}],"execution_count":13}]}